{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_c6fa6I6ZkfD",
    "outputId": "0357c0de-41fb-48f5-b9b8-94d81206febf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vignesh-aravindh-b/Documents/myenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt_tab to /home/vignesh-\n",
      "[nltk_data]     aravindh-b/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/vignesh-\n",
      "[nltk_data]     aravindh-b/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/vignesh-aravindh-b/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/vignesh-\n",
      "[nltk_data]     aravindh-b/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import proselint\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "from nltk import pos_tag, word_tokenize\n",
    "import copy\n",
    "import swifter\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "5ybm80jgZ0no",
    "outputId": "1e5e246c-f149-4cc0-8b71-7536bbba1010"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.tsv\", sep = '\\t')\n",
    "test_df = pd.read_csv(\"test.tsv\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2619</td>\n",
       "      <td>Ex-CIA head says Trump remarks on Russia inter...</td>\n",
       "      <td>Former CIA director John Brennan on Friday cri...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>July 22, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16043</td>\n",
       "      <td>YOU WON’T BELIEVE HIS PUNISHMENT! HISPANIC STO...</td>\n",
       "      <td>How did this man come to OWN this store? There...</td>\n",
       "      <td>Government News</td>\n",
       "      <td>Jun 19, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>876</td>\n",
       "      <td>Federal Reserve governor Powell's policy views...</td>\n",
       "      <td>President Donald Trump on Thursday tapped Fede...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>November 2, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19963</td>\n",
       "      <td>SCOUNDREL HILLARY SUPPORTER STARTS “TrumpLeaks...</td>\n",
       "      <td>Hillary Clinton ally David Brock is offering t...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Sep 17, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10783</td>\n",
       "      <td>NANCY PELOSI ARROGANTLY DISMISSES Questions on...</td>\n",
       "      <td>Pleading ignorance is a perfect ploy for Nancy...</td>\n",
       "      <td>politics</td>\n",
       "      <td>May 26, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        2619  Ex-CIA head says Trump remarks on Russia inter...   \n",
       "1       16043  YOU WON’T BELIEVE HIS PUNISHMENT! HISPANIC STO...   \n",
       "2         876  Federal Reserve governor Powell's policy views...   \n",
       "3       19963  SCOUNDREL HILLARY SUPPORTER STARTS “TrumpLeaks...   \n",
       "4       10783  NANCY PELOSI ARROGANTLY DISMISSES Questions on...   \n",
       "\n",
       "                                                text          subject  \\\n",
       "0  Former CIA director John Brennan on Friday cri...     politicsNews   \n",
       "1  How did this man come to OWN this store? There...  Government News   \n",
       "2  President Donald Trump on Thursday tapped Fede...     politicsNews   \n",
       "3  Hillary Clinton ally David Brock is offering t...        left-news   \n",
       "4  Pleading ignorance is a perfect ploy for Nancy...         politics   \n",
       "\n",
       "                date  label  \n",
       "0     July 22, 2017       1  \n",
       "1       Jun 19, 2017      0  \n",
       "2  November 2, 2017       1  \n",
       "3       Sep 17, 2016      0  \n",
       "4       May 26, 2017      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2619</td>\n",
       "      <td>Ex-CIA head says Trump remarks on Russia inter...</td>\n",
       "      <td>Former CIA director John Brennan on Friday cri...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>July 22, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16043</td>\n",
       "      <td>YOU WON’T BELIEVE HIS PUNISHMENT! HISPANIC STO...</td>\n",
       "      <td>How did this man come to OWN this store? There...</td>\n",
       "      <td>Government News</td>\n",
       "      <td>Jun 19, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>876</td>\n",
       "      <td>Federal Reserve governor Powell's policy views...</td>\n",
       "      <td>President Donald Trump on Thursday tapped Fede...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>November 2, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19963</td>\n",
       "      <td>SCOUNDREL HILLARY SUPPORTER STARTS “TrumpLeaks...</td>\n",
       "      <td>Hillary Clinton ally David Brock is offering t...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Sep 17, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10783</td>\n",
       "      <td>NANCY PELOSI ARROGANTLY DISMISSES Questions on...</td>\n",
       "      <td>Pleading ignorance is a perfect ploy for Nancy...</td>\n",
       "      <td>politics</td>\n",
       "      <td>May 26, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        2619  Ex-CIA head says Trump remarks on Russia inter...   \n",
       "1       16043  YOU WON’T BELIEVE HIS PUNISHMENT! HISPANIC STO...   \n",
       "2         876  Federal Reserve governor Powell's policy views...   \n",
       "3       19963  SCOUNDREL HILLARY SUPPORTER STARTS “TrumpLeaks...   \n",
       "4       10783  NANCY PELOSI ARROGANTLY DISMISSES Questions on...   \n",
       "\n",
       "                                                text          subject  \\\n",
       "0  Former CIA director John Brennan on Friday cri...     politicsNews   \n",
       "1  How did this man come to OWN this store? There...  Government News   \n",
       "2  President Donald Trump on Thursday tapped Fede...     politicsNews   \n",
       "3  Hillary Clinton ally David Brock is offering t...        left-news   \n",
       "4  Pleading ignorance is a perfect ploy for Nancy...         politics   \n",
       "\n",
       "                date  label  \n",
       "0     July 22, 2017       1  \n",
       "1       Jun 19, 2017      0  \n",
       "2  November 2, 2017       1  \n",
       "3       Sep 17, 2016      0  \n",
       "4       May 26, 2017      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_df = copy.deepcopy(train_df)\n",
    "new_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWSdy9_dagaE"
   },
   "source": [
    "## Step 1 : Linguistic Features\n",
    "### Punctuation Check\n",
    "### Grammar Check\n",
    "### Readability Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30000/30000 [01:03<00:00, 474.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# # Punctuation\n",
    "# text1 = \"Hello my name is Aditya I love coding!!!!!! but, sometimes I make mistakes\"\n",
    "# issues = proselint.tools.lint(text1)\n",
    "# if(not len(issues)):\n",
    "#     print(\"No Puntuation issues found\")\n",
    "# else:\n",
    "#     print(\"Issues Found\")\n",
    "i = 0\n",
    "def check_punctuation(headline):\n",
    "    issues = proselint.tools.lint(headline)\n",
    "    if(not len(issues)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "new_train_df['Punctuate'] = new_train_df['title'].swifter.apply(check_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     0\n",
       "2     1\n",
       "3     0\n",
       "4     1\n",
       "5     1\n",
       "6     1\n",
       "7     1\n",
       "8     1\n",
       "9     1\n",
       "10    1\n",
       "11    1\n",
       "12    1\n",
       "13    1\n",
       "14    1\n",
       "15    1\n",
       "16    1\n",
       "17    1\n",
       "18    1\n",
       "19    1\n",
       "Name: Punctuate, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_train_df['Punctuate'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bR6ID679aFz0",
    "outputId": "2a0ce0ba-4f09-4941-d67c-668742e42552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hyperbolic.misc', \"'coding!!!!!!' is hyperbolic.\", 0, 31, 31, 44, 13, 'warning', None), ('leonard.exclamation.30ppm', 'More than 30 ppm of exclamations. Keep them under control.', 0, 37, 37, 38, 1, 'warning', None), ('leonard.exclamation.multiple', 'Stop yelling. Keep your exclamation points under control.', 0, 38, 38, 43, 5, 'warning', None)]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(issues)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m issue \u001b[38;5;129;01min\u001b[39;00m issues:\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIssue: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43missue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Grammar\u001b[39;00m\n\u001b[1;32m     11\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# Grammar\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def grammar_check(text):\n",
    "    doc = nlp(text)\n",
    "    issues = []\n",
    "\n",
    "    for token in doc:\n",
    "        # Check if the subject-verb agreement seems off\n",
    "        if token.dep_ == \"nsubj\" and token.head.pos_ == \"VERB\":\n",
    "            if token.tag_ in [\"NN\", \"NNP\"] and token.head.tag_ == \"VBP\":\n",
    "                issues.append(f\"Issue: Singular subject '{token.text}' with plural verb '{token.head.text}'\")\n",
    "            elif token.tag_ in [\"NNS\"] and token.head.tag_ == \"VBZ\":\n",
    "                issues.append(f\"Issue: Plural subject '{token.text}' with singular verb '{token.head.text}'\")\n",
    "\n",
    "        # Flag any auxiliary verbs that don't seem to match the context\n",
    "        if token.dep_ == \"aux\" and token.head.pos_ == \"VERB\":\n",
    "            if token.text.lower() in [\"is\", \"was\"] and token.head.tag_ == \"VBP\":\n",
    "                issues.append(f\"Issue: Incorrect auxiliary verb '{token.text}' for verb '{token.head.text}'\")\n",
    "\n",
    "    return issues\n",
    "\n",
    "# Example text\n",
    "text1 = \"Breaking news world leader meets to !!!!!!discuss climate change.\"\n",
    "grammar_issues = grammar_check(text1)\n",
    "\n",
    "if grammar_issues:\n",
    "    print(\"Grammar Issues Found:\")\n",
    "    for issue in grammar_issues:\n",
    "        print(issue)\n",
    "else:\n",
    "    print(\"No grammar issues found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4vyJ6J5dXLL"
   },
   "source": [
    "## Step 2 : Keyword Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pY7H6daSedLj",
    "outputId": "6b310204-c8bd-4ecb-980b-022001b98cf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword density of 'shocking': 0.00%\n",
      "Keyword density of 'breaking': 0.00%\n",
      "Keyword density of 'exclusive': 0.00%\n",
      "Keyword density of 'unbelievable': 0.00%\n",
      "Keyword density of 'amazing': 0.00%\n",
      "Keyword density of 'incredible': 0.00%\n",
      "Keyword density of 'dramatic': 0.00%\n",
      "Keyword density of 'jaw-dropping': 0.00%\n",
      "Keyword density of 'sensational': 0.00%\n",
      "Keyword density of 'revealed': 0.00%\n",
      "Keyword density of 'uncovered': 0.00%\n",
      "Keyword density of 'startling': 0.00%\n",
      "Keyword density of 'bizarre': 0.00%\n",
      "Keyword density of 'explosive': 0.00%\n",
      "Keyword density of 'unprecedented': 0.00%\n",
      "Keyword density of 'unexpected': 0.00%\n",
      "Keyword density of 'mind-blowing': 0.00%\n",
      "Keyword density of 'stunning': 0.00%\n",
      "Keyword density of 'outrageous': 0.00%\n",
      "Keyword density of 'scandalous': 0.00%\n",
      "Keyword density of 'astonishing': 0.00%\n",
      "Keyword density of 'shocking': 0.00%\n"
     ]
    }
   ],
   "source": [
    "def keyword_density(text, keyword):\n",
    "    \"\"\"Calculates keyword density.\n",
    "\n",
    "    Args:\n",
    "        text: The input text.\n",
    "        keyword: The keyword to analyze.\n",
    "\n",
    "    Returns:\n",
    "        The keyword density as a percentage.\n",
    "    \"\"\"\n",
    "\n",
    "    # Tokenize the text and remove stop words\n",
    "    words = [word.lower() for word in nltk.word_tokenize(text) if word.lower() not in stopwords.words('english') and word.isalnum()]\n",
    "\n",
    "    # Count the occurrences of the keyword\n",
    "    keyword_count = words.count(keyword.lower())\n",
    "\n",
    "    # Calculate the keyword density\n",
    "    density = (keyword_count / len(words)) * 100 if words else 0\n",
    "\n",
    "    return density\n",
    "\n",
    "text2 = \"BONKERS BERNIE SANDERS: Prioritizing Jobs Over Climate Change Is ‘Stupid and Dangerous’ [Video]\thttps://www.youtube.com/watch?v=GPqQIlWksbgVermont Sen. Bernard Sanders told CNN Thursday that President Trump s plan to prioritize job creation over climate change regulations is  stupid and dangerous.  The commander in chief signed an  Energy Independence  executive order Tuesday as a means of rolling back former President Barack Obama s Clean Power Plan. Mr. Trump said his policies will cause  wealth to pour into our communities,  although Mr. Sanders frames it as a recipe for environmental disaster.  [This plan is a] nonsensical, and stupid, and dangerous approach,  Mr. Sanders told CNN s Wolf Blitzer Thursday.  It s almost indescribable. Look, the scientific community is virtually unanimous. While Trump and his friends think climate change is a hoax, what the scientists are telling us it is real, it is caused by human activity. It is already causing devastating problems.  The Trump administration argues on the White House website that its actions will prevent $39 billion in electricity hikes, allow 242 million tons of coal to benefit the American economy, and disbands the Interagency Working Group on the Social Cost of Greenhouse Gases.  I am taking historic steps to lift restrictions on American energy, to reverse government intrusion and to cancel job-killing regulations,  Mr. Trump said Tuesday while surrounded by coal industry executives. Kentucky Coal Association President Tyler White cheered the move soon afterward.Read more: WT\tpolitics.\"\n",
    "sensational_words = [\n",
    "    \"shocking\", \"breaking\", \"exclusive\", \"unbelievable\", \"amazing\", \"incredible\",\n",
    "    \"dramatic\", \"jaw-dropping\", \"sensational\", \"revealed\", \"uncovered\", \"startling\",\n",
    "    \"bizarre\", \"explosive\", \"unprecedented\", \"unexpected\", \"mind-blowing\", \"stunning\",\n",
    "    \"outrageous\", \"scandalous\", \"astonishing\", \"shocking\"\n",
    "]\n",
    "\n",
    "densities = {}\n",
    "\n",
    "for keyword in sensational_words:\n",
    "    density = keyword_density(text2, keyword)\n",
    "    print(f\"Keyword density of '{keyword}': {density:.2f}%\")\n",
    "    densities[keyword] = density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RDpxH3vyh3h5",
    "outputId": "1078e788-5976-482f-8052-0442337c075d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens : ['Breaking', 'news', '.', 'A', 'person', 'is', 'blasting', 'himself', '.']\n",
      "Tags : [('Breaking', 'VBG'), ('news', 'NN'), ('.', '.'), ('A', 'DT'), ('person', 'NN'), ('is', 'VBZ'), ('blasting', 'VBG'), ('himself', 'PRP'), ('.', '.')]\n",
      "['Breaking', 'blasting']\n",
      "2\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "headline = \"Breaking news. A person is blasting himself.\"\n",
    "\n",
    "# Tokenize and POS tag\n",
    "text2 = \" \".join(sensational_words)\n",
    "\n",
    "tokens = word_tokenize(headline)\n",
    "tags = pos_tag(tokens)\n",
    "\n",
    "print(f\"Tokens : {tokens}\")\n",
    "print(f\"Tags : {tags}\")\n",
    "\n",
    "\n",
    "# Extract adjectives (JJ) and adverbs (RB)\n",
    "important_words = [word for word, tag in tags if tag in ['JJ', 'RB', 'VBG']]\n",
    "print(important_words)\n",
    "\n",
    "print(len(important_words))\n",
    "print(len(sensational_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GIlat4s-grpa",
    "outputId": "be41a123-8386-4a37-8ffd-bf0c018b38bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['Breaking', 'news', '.', 'A', 'person', 'is', 'blasting', 'himself', '.']\n",
      "Tags: [('Breaking', 'VBG'), ('news', 'NN'), ('.', '.'), ('A', 'DT'), ('person', 'NN'), ('is', 'VBZ'), ('blasting', 'VBG'), ('himself', 'PRP'), ('.', '.')]\n",
      "Important words: ['Breaking', 'blasting']\n",
      "Sensational words: ['Breaking']\n",
      "Sensational word count: 1\n"
     ]
    }
   ],
   "source": [
    "from duckduckgo_search import DDGS\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import re\n",
    "\n",
    "def get_sensational_score(word):\n",
    "    try:\n",
    "        with DDGS() as ddgs:\n",
    "            search_query = f'\"{word}\" \"sensational journalism\" OR \"clickbait\"'\n",
    "            results = list(ddgs.text(search_query, max_results=10))\n",
    "            return len(results)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def analyze_headline(headline):\n",
    "    tokens = word_tokenize(headline)\n",
    "    tags = pos_tag(tokens)\n",
    "    important_words = [word for word, tag in tags if tag in ['JJ', 'RB', 'VBG']]\n",
    "\n",
    "    sensational_words = []\n",
    "    for word in important_words:\n",
    "        score = get_sensational_score(word)\n",
    "        if score > 2:\n",
    "            sensational_words.append(word)\n",
    "\n",
    "    return {\n",
    "        'tokens': tokens,\n",
    "        'tags': tags,\n",
    "        'important_words': important_words,\n",
    "        'sensational_words': sensational_words\n",
    "    }\n",
    "\n",
    "headline = \"Breaking news. A person is blasting himself.\"\n",
    "results = analyze_headline(headline)\n",
    "\n",
    "print(f\"Tokens: {results['tokens']}\")\n",
    "print(f\"Tags: {results['tags']}\")\n",
    "print(f\"Important words: {results['important_words']}\")\n",
    "print(f\"Sensational words: {results['sensational_words']}\")\n",
    "print(f\"Sensational word count: {len(results['sensational_words'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "7xnkFoCYiBcU"
   },
   "outputs": [],
   "source": [
    "new_train_df.to_csv('filename.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
