{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.tsv\",sep='\\t')\n",
    "test_df = pd.read_csv(\"test.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns = \"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat = pd.read_csv(\"train_categories.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tit_len = pd.read_csv(\"train_title_length.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_length = pd.read_csv(\"train_text_length.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_train_outputs_text = pd.read_csv(\"vader_train_outputs_text.csv\")\n",
    "vader_train_outputs_title = pd.read_csv(\"vader_train_outputs_title.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuated_train_df = pd.read_csv('punctuate_train.csv')\n",
    "punctuated_test_df = pd.read_csv('punctuate_test.csv')\n",
    "punctuated_test_df = punctuated_test_df['Punctuate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_train_title = pd.read_csv('title_keyword_density.tsv', sep = '\\t')\n",
    "keyword_train_text = pd.read_csv('text_keyword_density.tsv', sep = '\\t')\n",
    "\n",
    "keyword_test_title = pd.read_csv('test_title_keyword_density.tsv', sep = '\\t')\n",
    "keyword_test_text = pd.read_csv('test_text_keyword_density.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>title_char_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>text_char_count</th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>text_sentence_count</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>Punctuate</th>\n",
       "      <th>JJ_density</th>\n",
       "      <th>VBG_density</th>\n",
       "      <th>RB_density</th>\n",
       "      <th>JJ_text</th>\n",
       "      <th>VBG_text</th>\n",
       "      <th>RB_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>8</td>\n",
       "      <td>2733</td>\n",
       "      <td>257</td>\n",
       "      <td>16</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-0.5574</td>\n",
       "      <td>1</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.536779</td>\n",
       "      <td>1.988072</td>\n",
       "      <td>2.584493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "      <td>14</td>\n",
       "      <td>2630</td>\n",
       "      <td>271</td>\n",
       "      <td>14</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.073</td>\n",
       "      <td>-0.9197</td>\n",
       "      <td>0</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.384458</td>\n",
       "      <td>2.862986</td>\n",
       "      <td>2.658487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>4052</td>\n",
       "      <td>404</td>\n",
       "      <td>13</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>1</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.311902</td>\n",
       "      <td>1.778386</td>\n",
       "      <td>2.599179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "      <td>7</td>\n",
       "      <td>1131</td>\n",
       "      <td>107</td>\n",
       "      <td>5</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.9335</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.615385</td>\n",
       "      <td>2.403846</td>\n",
       "      <td>1.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>104</td>\n",
       "      <td>10</td>\n",
       "      <td>1061</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.4559</td>\n",
       "      <td>1</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>11.475410</td>\n",
       "      <td>2.732240</td>\n",
       "      <td>2.185792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_id  title_char_count  title_word_count  text_char_count  \\\n",
       "0            1                67                 8             2733   \n",
       "1            2               121                14             2630   \n",
       "2            1                64                 7             4052   \n",
       "3            3                72                 7             1131   \n",
       "4            4               104                10             1061   \n",
       "\n",
       "   text_word_count  text_sentence_count    neg    neu    pos  compound  \\\n",
       "0              257                   16  0.109  0.789  0.102   -0.5574   \n",
       "1              271                   14  0.095  0.832  0.073   -0.9197   \n",
       "2              404                   13  0.052  0.859  0.089    0.9826   \n",
       "3              107                    5  0.022  0.884  0.094    0.9335   \n",
       "4              100                    7  0.077  0.836  0.087    0.4559   \n",
       "\n",
       "   Punctuate  JJ_density  VBG_density  RB_density    JJ_text  VBG_text  \\\n",
       "0          1   10.000000          0.0    0.000000  10.536779  1.988072   \n",
       "1          0    4.347826          0.0    0.000000   8.384458  2.862986   \n",
       "2          1   16.666667          0.0    0.000000  12.311902  1.778386   \n",
       "3          0   20.000000          0.0    0.000000   9.615385  2.403846   \n",
       "4          1    6.666667          0.0    6.666667  11.475410  2.732240   \n",
       "\n",
       "    RB_text  \n",
       "0  2.584493  \n",
       "1  2.658487  \n",
       "2  2.599179  \n",
       "3  1.923077  \n",
       "4  2.185792  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.concat([train_cat, train_tit_len, train_text_length, \n",
    "                       vader_train_outputs_text, vader_train_outputs_title, punctuated_train_df, keyword_train_title, keyword_train_text], axis=1)\n",
    "merged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]\n",
    "merged_df.drop(columns=[\"id\", \"Unnamed: 0\"],inplace=True)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "print(len(merged_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.head()\n",
    "# print(len(train_df['label']), len(merged_df))\n",
    "# train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(merged_df, train_df['label'], test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>title_char_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>text_char_count</th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>text_sentence_count</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>Punctuate</th>\n",
       "      <th>JJ_density</th>\n",
       "      <th>VBG_density</th>\n",
       "      <th>RB_density</th>\n",
       "      <th>JJ_text</th>\n",
       "      <th>VBG_text</th>\n",
       "      <th>RB_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>346</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.9313</td>\n",
       "      <td>0</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.516129</td>\n",
       "      <td>1.612903</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>3518</td>\n",
       "      <td>346</td>\n",
       "      <td>21</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>1</td>\n",
       "      <td>7.692308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.370200</td>\n",
       "      <td>2.304147</td>\n",
       "      <td>1.689708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>142</td>\n",
       "      <td>16</td>\n",
       "      <td>2792</td>\n",
       "      <td>255</td>\n",
       "      <td>20</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.9777</td>\n",
       "      <td>1</td>\n",
       "      <td>13.636364</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>8.928571</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>3.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>58</td>\n",
       "      <td>8</td>\n",
       "      <td>2095</td>\n",
       "      <td>215</td>\n",
       "      <td>9</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.096</td>\n",
       "      <td>-0.6625</td>\n",
       "      <td>1</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.924119</td>\n",
       "      <td>3.523035</td>\n",
       "      <td>2.981030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>121</td>\n",
       "      <td>16</td>\n",
       "      <td>922</td>\n",
       "      <td>92</td>\n",
       "      <td>4</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>1</td>\n",
       "      <td>13.793103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.448276</td>\n",
       "      <td>6.806283</td>\n",
       "      <td>2.094241</td>\n",
       "      <td>4.712042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23995</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "      <td>5705</td>\n",
       "      <td>566</td>\n",
       "      <td>36</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>1</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.414560</td>\n",
       "      <td>3.741153</td>\n",
       "      <td>2.527806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>9</td>\n",
       "      <td>757</td>\n",
       "      <td>76</td>\n",
       "      <td>5</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>1</td>\n",
       "      <td>18.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.904110</td>\n",
       "      <td>2.739726</td>\n",
       "      <td>3.424658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>10</td>\n",
       "      <td>473</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.7311</td>\n",
       "      <td>1</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.862745</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.960784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23998</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>956</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.9538</td>\n",
       "      <td>1</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.714286</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23999</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>8</td>\n",
       "      <td>2533</td>\n",
       "      <td>252</td>\n",
       "      <td>16</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.9901</td>\n",
       "      <td>1</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.172260</td>\n",
       "      <td>2.460850</td>\n",
       "      <td>2.013423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       category_id  title_char_count  title_word_count  text_char_count  \\\n",
       "0                4                51                 8              346   \n",
       "1                1                72                 9             3518   \n",
       "2                3               142                16             2792   \n",
       "3                7                58                 8             2095   \n",
       "4                3               121                16              922   \n",
       "...            ...               ...               ...              ...   \n",
       "23995            1                51                 6             5705   \n",
       "23996            5                66                 9              757   \n",
       "23997            1                78                10              473   \n",
       "23998            3                60                 8              956   \n",
       "23999            1                63                 8             2533   \n",
       "\n",
       "       text_word_count  text_sentence_count    neg    neu    pos  compound  \\\n",
       "0                   34                    2  0.000  0.755  0.245    0.9313   \n",
       "1                  346                   21  0.042  0.869  0.089    0.9682   \n",
       "2                  255                   20  0.082  0.886  0.032   -0.9777   \n",
       "3                  215                    9  0.110  0.793  0.096   -0.6625   \n",
       "4                   92                    4  0.100  0.795  0.105    0.2462   \n",
       "...                ...                  ...    ...    ...    ...       ...   \n",
       "23995              566                   36  0.050  0.819  0.131    0.9981   \n",
       "23996               76                    5  0.014  0.919  0.067    0.8074   \n",
       "23997               51                    4  0.082  0.918  0.000   -0.7311   \n",
       "23998              100                    8  0.160  0.782  0.058   -0.9538   \n",
       "23999              252                   16  0.132  0.824  0.044   -0.9901   \n",
       "\n",
       "       Punctuate  JJ_density  VBG_density  RB_density    JJ_text  VBG_text  \\\n",
       "0              0    8.333333     0.000000    0.000000  14.516129  1.612903   \n",
       "1              1    7.692308     0.000000    0.000000   9.370200  2.304147   \n",
       "2              1   13.636364     4.545455    4.545455   8.928571  1.785714   \n",
       "3              1   20.000000     0.000000    0.000000  11.924119  3.523035   \n",
       "4              1   13.793103     0.000000    3.448276   6.806283  2.094241   \n",
       "...          ...         ...          ...         ...        ...       ...   \n",
       "23995          1   42.857143     0.000000    0.000000  10.414560  3.741153   \n",
       "23996          1   18.181818     0.000000    0.000000   8.904110  2.739726   \n",
       "23997          1    6.666667     0.000000    0.000000   6.862745  0.980392   \n",
       "23998          1   20.000000    10.000000    0.000000  13.714286  1.142857   \n",
       "23999          1    9.090909     0.000000    0.000000   9.172260  2.460850   \n",
       "\n",
       "        RB_text  \n",
       "0      0.000000  \n",
       "1      1.689708  \n",
       "2      3.214286  \n",
       "3      2.981030  \n",
       "4      4.712042  \n",
       "...         ...  \n",
       "23995  2.527806  \n",
       "23996  3.424658  \n",
       "23997  1.960784  \n",
       "23998  0.571429  \n",
       "23999  2.013423  \n",
       "\n",
       "[24000 rows x 17 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reset_index(drop = True)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reset_index(drop = True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train.values, dtype = torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype = torch.long)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype = torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\" if not torch.cuda.is_available() else \"gpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvolutionalNetwork(\n",
      "  (conv_layer): Sequential(\n",
      "    (0): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): Tanh()\n",
      "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (4): Tanh()\n",
      "    (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (7): Tanh()\n",
      "    (8): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (10): Tanh()\n",
      "    (11): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (13): Tanh()\n",
      "  )\n",
      "  (fc_layer): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=128, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class ConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionalNetwork, self).__init__()\n",
    "\n",
    "        # More dense 1D Convolutional layers\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1),  # (64, 17)\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool1d(kernel_size=2),  # (64, 8)\n",
    "\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1),  # (128, 8)\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool1d(kernel_size=2),  # (128, 4)\n",
    "\n",
    "            nn.Conv1d(128, 256, kernel_size=3, stride=1, padding=1),  # (256, 4)\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool1d(kernel_size=2),  # (256, 2)\n",
    "\n",
    "            nn.Conv1d(256, 512, kernel_size=3, stride=1, padding=1),  # (512, 2)\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool1d(kernel_size=2),  # (512, 1)\n",
    "\n",
    "            nn.Conv1d(512, 1024, kernel_size=3, stride=1, padding=1),  # (1024, 1)\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "        # Fully connected layers after the convolutional layers\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(1024, 512),  # Flattened input to the fully connected layer (1024 channels)\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2),  # Output layer for binary classification\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), 1, 17)  # Reshape input to [batch_size, 1, 17]\n",
    "        x = self.conv_layer(x)  # Apply convolutional layers\n",
    "        x = torch.flatten(x, 1)  # Flatten the tensor before feeding it into the fully connected layers\n",
    "        x = self.fc_layer(x)  # Apply fully connected layers\n",
    "        return x\n",
    "    \n",
    "model = ConvolutionalNetwork().to(device)\n",
    "print(model)\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.699351  [   32/24000]\n",
      "loss: 0.547406  [ 3232/24000]\n",
      "loss: 0.459146  [ 6432/24000]\n",
      "loss: 0.347260  [ 9632/24000]\n",
      "loss: 0.381818  [12832/24000]\n",
      "loss: 0.543382  [16032/24000]\n",
      "loss: 0.497993  [19232/24000]\n",
      "loss: 0.546261  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.333048 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.265802  [   32/24000]\n",
      "loss: 0.283830  [ 3232/24000]\n",
      "loss: 0.247727  [ 6432/24000]\n",
      "loss: 0.316545  [ 9632/24000]\n",
      "loss: 0.256373  [12832/24000]\n",
      "loss: 0.242296  [16032/24000]\n",
      "loss: 0.335756  [19232/24000]\n",
      "loss: 0.429695  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.334491 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.277580  [   32/24000]\n",
      "loss: 0.306622  [ 3232/24000]\n",
      "loss: 0.425371  [ 6432/24000]\n",
      "loss: 0.309131  [ 9632/24000]\n",
      "loss: 0.271209  [12832/24000]\n",
      "loss: 0.244274  [16032/24000]\n",
      "loss: 0.461502  [19232/24000]\n",
      "loss: 0.205890  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.271018 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.167376  [   32/24000]\n",
      "loss: 0.189659  [ 3232/24000]\n",
      "loss: 0.286504  [ 6432/24000]\n",
      "loss: 0.265030  [ 9632/24000]\n",
      "loss: 0.310711  [12832/24000]\n",
      "loss: 0.120678  [16032/24000]\n",
      "loss: 0.358885  [19232/24000]\n",
      "loss: 0.178957  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.223399 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.178971  [   32/24000]\n",
      "loss: 0.259760  [ 3232/24000]\n",
      "loss: 0.291781  [ 6432/24000]\n",
      "loss: 0.263447  [ 9632/24000]\n",
      "loss: 0.183646  [12832/24000]\n",
      "loss: 0.290590  [16032/24000]\n",
      "loss: 0.303915  [19232/24000]\n",
      "loss: 0.253830  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.191358 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.106737  [   32/24000]\n",
      "loss: 0.080791  [ 3232/24000]\n",
      "loss: 0.230729  [ 6432/24000]\n",
      "loss: 0.164802  [ 9632/24000]\n",
      "loss: 0.322820  [12832/24000]\n",
      "loss: 0.166088  [16032/24000]\n",
      "loss: 0.235331  [19232/24000]\n",
      "loss: 0.170798  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 93.1%, Avg loss: 0.183208 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.151818  [   32/24000]\n",
      "loss: 0.197957  [ 3232/24000]\n",
      "loss: 0.142192  [ 6432/24000]\n",
      "loss: 0.434580  [ 9632/24000]\n",
      "loss: 0.174757  [12832/24000]\n",
      "loss: 0.145033  [16032/24000]\n",
      "loss: 0.164197  [19232/24000]\n",
      "loss: 0.233645  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.161546 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.177989  [   32/24000]\n",
      "loss: 0.229499  [ 3232/24000]\n",
      "loss: 0.140582  [ 6432/24000]\n",
      "loss: 0.159505  [ 9632/24000]\n",
      "loss: 0.119159  [12832/24000]\n",
      "loss: 0.225506  [16032/24000]\n",
      "loss: 0.068096  [19232/24000]\n",
      "loss: 0.167120  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.190971 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.131328  [   32/24000]\n",
      "loss: 0.101491  [ 3232/24000]\n",
      "loss: 0.132106  [ 6432/24000]\n",
      "loss: 0.123364  [ 9632/24000]\n",
      "loss: 0.090781  [12832/24000]\n",
      "loss: 0.064646  [16032/24000]\n",
      "loss: 0.162799  [19232/24000]\n",
      "loss: 0.452139  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.159709 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.329166  [   32/24000]\n",
      "loss: 0.114889  [ 3232/24000]\n",
      "loss: 0.197056  [ 6432/24000]\n",
      "loss: 0.377437  [ 9632/24000]\n",
      "loss: 0.235786  [12832/24000]\n",
      "loss: 0.202555  [16032/24000]\n",
      "loss: 0.375015  [19232/24000]\n",
      "loss: 0.035560  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 94.4%, Avg loss: 0.156845 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.113517  [   32/24000]\n",
      "loss: 0.140149  [ 3232/24000]\n",
      "loss: 0.048485  [ 6432/24000]\n",
      "loss: 0.056870  [ 9632/24000]\n",
      "loss: 0.284547  [12832/24000]\n",
      "loss: 0.171327  [16032/24000]\n",
      "loss: 0.166771  [19232/24000]\n",
      "loss: 0.051603  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.164611 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.070349  [   32/24000]\n",
      "loss: 0.216738  [ 3232/24000]\n",
      "loss: 0.079630  [ 6432/24000]\n",
      "loss: 0.030793  [ 9632/24000]\n",
      "loss: 0.175515  [12832/24000]\n",
      "loss: 0.288756  [16032/24000]\n",
      "loss: 0.219554  [19232/24000]\n",
      "loss: 0.199728  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 94.9%, Avg loss: 0.148707 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.148975  [   32/24000]\n",
      "loss: 0.056670  [ 3232/24000]\n",
      "loss: 0.140612  [ 6432/24000]\n",
      "loss: 0.076536  [ 9632/24000]\n",
      "loss: 0.296557  [12832/24000]\n",
      "loss: 0.127864  [16032/24000]\n",
      "loss: 0.036083  [19232/24000]\n",
      "loss: 0.139403  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.170129 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.141017  [   32/24000]\n",
      "loss: 0.100597  [ 3232/24000]\n",
      "loss: 0.244612  [ 6432/24000]\n",
      "loss: 0.026199  [ 9632/24000]\n",
      "loss: 0.226599  [12832/24000]\n",
      "loss: 0.194302  [16032/24000]\n",
      "loss: 0.082463  [19232/24000]\n",
      "loss: 0.099087  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.146084 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.244452  [   32/24000]\n",
      "loss: 0.148677  [ 3232/24000]\n",
      "loss: 0.210089  [ 6432/24000]\n",
      "loss: 0.096215  [ 9632/24000]\n",
      "loss: 0.436705  [12832/24000]\n",
      "loss: 0.109379  [16032/24000]\n",
      "loss: 0.138203  [19232/24000]\n",
      "loss: 0.029278  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 94.8%, Avg loss: 0.145777 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.047287  [   32/24000]\n",
      "loss: 0.297858  [ 3232/24000]\n",
      "loss: 0.052631  [ 6432/24000]\n",
      "loss: 0.136330  [ 9632/24000]\n",
      "loss: 0.207341  [12832/24000]\n",
      "loss: 0.266662  [16032/24000]\n",
      "loss: 0.124309  [19232/24000]\n",
      "loss: 0.276085  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.146048 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.054900  [   32/24000]\n",
      "loss: 0.188326  [ 3232/24000]\n",
      "loss: 0.046743  [ 6432/24000]\n",
      "loss: 0.291942  [ 9632/24000]\n",
      "loss: 0.396052  [12832/24000]\n",
      "loss: 0.024968  [16032/24000]\n",
      "loss: 0.057129  [19232/24000]\n",
      "loss: 0.238118  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 94.8%, Avg loss: 0.146544 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.041870  [   32/24000]\n",
      "loss: 0.061166  [ 3232/24000]\n",
      "loss: 0.125927  [ 6432/24000]\n",
      "loss: 0.214480  [ 9632/24000]\n",
      "loss: 0.127444  [12832/24000]\n",
      "loss: 0.125846  [16032/24000]\n",
      "loss: 0.388435  [19232/24000]\n",
      "loss: 0.435444  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Avg loss: 0.143792 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.145030  [   32/24000]\n",
      "loss: 0.061479  [ 3232/24000]\n",
      "loss: 0.051153  [ 6432/24000]\n",
      "loss: 0.289366  [ 9632/24000]\n",
      "loss: 0.078595  [12832/24000]\n",
      "loss: 0.041316  [16032/24000]\n",
      "loss: 0.065942  [19232/24000]\n",
      "loss: 0.256954  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.142379 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.039711  [   32/24000]\n",
      "loss: 0.273636  [ 3232/24000]\n",
      "loss: 0.125215  [ 6432/24000]\n",
      "loss: 0.080929  [ 9632/24000]\n",
      "loss: 0.099778  [12832/24000]\n",
      "loss: 0.081546  [16032/24000]\n",
      "loss: 0.407476  [19232/24000]\n",
      "loss: 0.115553  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 94.8%, Avg loss: 0.142697 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.189998  [   32/24000]\n",
      "loss: 0.047791  [ 3232/24000]\n",
      "loss: 0.201287  [ 6432/24000]\n",
      "loss: 0.267064  [ 9632/24000]\n",
      "loss: 0.057452  [12832/24000]\n",
      "loss: 0.112572  [16032/24000]\n",
      "loss: 0.091191  [19232/24000]\n",
      "loss: 0.214112  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.142663 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.130192  [   32/24000]\n",
      "loss: 0.187592  [ 3232/24000]\n",
      "loss: 0.026812  [ 6432/24000]\n",
      "loss: 0.050507  [ 9632/24000]\n",
      "loss: 0.047499  [12832/24000]\n",
      "loss: 0.197883  [16032/24000]\n",
      "loss: 0.016657  [19232/24000]\n",
      "loss: 0.068562  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 95.3%, Avg loss: 0.137433 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.202306  [   32/24000]\n",
      "loss: 0.095992  [ 3232/24000]\n",
      "loss: 0.017995  [ 6432/24000]\n",
      "loss: 0.093418  [ 9632/24000]\n",
      "loss: 0.071952  [12832/24000]\n",
      "loss: 0.058335  [16032/24000]\n",
      "loss: 0.050770  [19232/24000]\n",
      "loss: 0.215811  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.131442 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.066485  [   32/24000]\n",
      "loss: 0.046234  [ 3232/24000]\n",
      "loss: 0.091133  [ 6432/24000]\n",
      "loss: 0.116596  [ 9632/24000]\n",
      "loss: 0.114460  [12832/24000]\n",
      "loss: 0.077888  [16032/24000]\n",
      "loss: 0.190253  [19232/24000]\n",
      "loss: 0.127598  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.147832 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.210391  [   32/24000]\n",
      "loss: 0.172667  [ 3232/24000]\n",
      "loss: 0.170246  [ 6432/24000]\n",
      "loss: 0.103328  [ 9632/24000]\n",
      "loss: 0.105209  [12832/24000]\n",
      "loss: 0.098033  [16032/24000]\n",
      "loss: 0.076725  [19232/24000]\n",
      "loss: 0.114834  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 95.4%, Avg loss: 0.133023 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.284099  [   32/24000]\n",
      "loss: 0.103325  [ 3232/24000]\n",
      "loss: 0.120985  [ 6432/24000]\n",
      "loss: 0.213942  [ 9632/24000]\n",
      "loss: 0.142668  [12832/24000]\n",
      "loss: 0.112687  [16032/24000]\n",
      "loss: 0.023906  [19232/24000]\n",
      "loss: 0.150681  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.130183 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.201716  [   32/24000]\n",
      "loss: 0.154728  [ 3232/24000]\n",
      "loss: 0.050240  [ 6432/24000]\n",
      "loss: 0.195652  [ 9632/24000]\n",
      "loss: 0.136547  [12832/24000]\n",
      "loss: 0.193133  [16032/24000]\n",
      "loss: 0.219510  [19232/24000]\n",
      "loss: 0.078064  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 95.7%, Avg loss: 0.124071 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.043707  [   32/24000]\n",
      "loss: 0.076203  [ 3232/24000]\n",
      "loss: 0.149485  [ 6432/24000]\n",
      "loss: 0.084968  [ 9632/24000]\n",
      "loss: 0.060825  [12832/24000]\n",
      "loss: 0.374067  [16032/24000]\n",
      "loss: 0.114635  [19232/24000]\n",
      "loss: 0.125155  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 95.3%, Avg loss: 0.128115 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.059014  [   32/24000]\n",
      "loss: 0.040918  [ 3232/24000]\n",
      "loss: 0.042743  [ 6432/24000]\n",
      "loss: 0.048354  [ 9632/24000]\n",
      "loss: 0.049787  [12832/24000]\n",
      "loss: 0.076088  [16032/24000]\n",
      "loss: 0.198652  [19232/24000]\n",
      "loss: 0.018875  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.138101 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.028014  [   32/24000]\n",
      "loss: 0.111527  [ 3232/24000]\n",
      "loss: 0.218182  [ 6432/24000]\n",
      "loss: 0.269444  [ 9632/24000]\n",
      "loss: 0.012550  [12832/24000]\n",
      "loss: 0.049031  [16032/24000]\n",
      "loss: 0.046953  [19232/24000]\n",
      "loss: 0.039818  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 95.7%, Avg loss: 0.121922 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.110898  [   32/24000]\n",
      "loss: 0.053031  [ 3232/24000]\n",
      "loss: 0.018828  [ 6432/24000]\n",
      "loss: 0.113246  [ 9632/24000]\n",
      "loss: 0.037863  [12832/24000]\n",
      "loss: 0.121326  [16032/24000]\n",
      "loss: 0.234287  [19232/24000]\n",
      "loss: 0.164289  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 96.1%, Avg loss: 0.110739 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.069108  [   32/24000]\n",
      "loss: 0.064562  [ 3232/24000]\n",
      "loss: 0.112036  [ 6432/24000]\n",
      "loss: 0.082883  [ 9632/24000]\n",
      "loss: 0.063968  [12832/24000]\n",
      "loss: 0.091708  [16032/24000]\n",
      "loss: 0.039380  [19232/24000]\n",
      "loss: 0.238190  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, Avg loss: 0.105339 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.027619  [   32/24000]\n",
      "loss: 0.007934  [ 3232/24000]\n",
      "loss: 0.024424  [ 6432/24000]\n",
      "loss: 0.020034  [ 9632/24000]\n",
      "loss: 0.122115  [12832/24000]\n",
      "loss: 0.023646  [16032/24000]\n",
      "loss: 0.020912  [19232/24000]\n",
      "loss: 0.116542  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.111554 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.029109  [   32/24000]\n",
      "loss: 0.138350  [ 3232/24000]\n",
      "loss: 0.016951  [ 6432/24000]\n",
      "loss: 0.107890  [ 9632/24000]\n",
      "loss: 0.049581  [12832/24000]\n",
      "loss: 0.006973  [16032/24000]\n",
      "loss: 0.020573  [19232/24000]\n",
      "loss: 0.116917  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, Avg loss: 0.108428 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.085836  [   32/24000]\n",
      "loss: 0.110409  [ 3232/24000]\n",
      "loss: 0.184583  [ 6432/24000]\n",
      "loss: 0.068199  [ 9632/24000]\n",
      "loss: 0.091552  [12832/24000]\n",
      "loss: 0.109813  [16032/24000]\n",
      "loss: 0.120809  [19232/24000]\n",
      "loss: 0.043711  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Avg loss: 0.098056 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.023352  [   32/24000]\n",
      "loss: 0.052604  [ 3232/24000]\n",
      "loss: 0.025828  [ 6432/24000]\n",
      "loss: 0.014715  [ 9632/24000]\n",
      "loss: 0.019029  [12832/24000]\n",
      "loss: 0.017841  [16032/24000]\n",
      "loss: 0.082214  [19232/24000]\n",
      "loss: 0.015136  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 94.3%, Avg loss: 0.145255 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.079259  [   32/24000]\n",
      "loss: 0.010841  [ 3232/24000]\n",
      "loss: 0.076924  [ 6432/24000]\n",
      "loss: 0.358319  [ 9632/24000]\n",
      "loss: 0.014460  [12832/24000]\n",
      "loss: 0.029727  [16032/24000]\n",
      "loss: 0.016424  [19232/24000]\n",
      "loss: 0.027994  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.103802 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.024077  [   32/24000]\n",
      "loss: 0.055428  [ 3232/24000]\n",
      "loss: 0.047563  [ 6432/24000]\n",
      "loss: 0.020051  [ 9632/24000]\n",
      "loss: 0.043429  [12832/24000]\n",
      "loss: 0.146638  [16032/24000]\n",
      "loss: 0.020513  [19232/24000]\n",
      "loss: 0.026018  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Avg loss: 0.086560 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.037136  [   32/24000]\n",
      "loss: 0.009351  [ 3232/24000]\n",
      "loss: 0.080009  [ 6432/24000]\n",
      "loss: 0.020397  [ 9632/24000]\n",
      "loss: 0.060562  [12832/24000]\n",
      "loss: 0.030389  [16032/24000]\n",
      "loss: 0.107192  [19232/24000]\n",
      "loss: 0.046729  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.088535 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.005128  [   32/24000]\n",
      "loss: 0.078655  [ 3232/24000]\n",
      "loss: 0.070400  [ 6432/24000]\n",
      "loss: 0.022412  [ 9632/24000]\n",
      "loss: 0.053474  [12832/24000]\n",
      "loss: 0.029835  [16032/24000]\n",
      "loss: 0.048780  [19232/24000]\n",
      "loss: 0.009776  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Avg loss: 0.095689 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.071982  [   32/24000]\n",
      "loss: 0.046992  [ 3232/24000]\n",
      "loss: 0.018148  [ 6432/24000]\n",
      "loss: 0.008287  [ 9632/24000]\n",
      "loss: 0.014886  [12832/24000]\n",
      "loss: 0.013831  [16032/24000]\n",
      "loss: 0.010502  [19232/24000]\n",
      "loss: 0.001905  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Avg loss: 0.096954 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.088434  [   32/24000]\n",
      "loss: 0.063979  [ 3232/24000]\n",
      "loss: 0.087768  [ 6432/24000]\n",
      "loss: 0.009992  [ 9632/24000]\n",
      "loss: 0.023034  [12832/24000]\n",
      "loss: 0.006179  [16032/24000]\n",
      "loss: 0.025382  [19232/24000]\n",
      "loss: 0.021193  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.078647 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.010668  [   32/24000]\n",
      "loss: 0.018510  [ 3232/24000]\n",
      "loss: 0.002465  [ 6432/24000]\n",
      "loss: 0.188007  [ 9632/24000]\n",
      "loss: 0.016998  [12832/24000]\n",
      "loss: 0.131207  [16032/24000]\n",
      "loss: 0.237167  [19232/24000]\n",
      "loss: 0.021007  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.092443 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.045087  [   32/24000]\n",
      "loss: 0.005507  [ 3232/24000]\n",
      "loss: 0.026275  [ 6432/24000]\n",
      "loss: 0.002985  [ 9632/24000]\n",
      "loss: 0.007697  [12832/24000]\n",
      "loss: 0.025481  [16032/24000]\n",
      "loss: 0.230909  [19232/24000]\n",
      "loss: 0.053270  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.078308 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.021570  [   32/24000]\n",
      "loss: 0.019360  [ 3232/24000]\n",
      "loss: 0.012308  [ 6432/24000]\n",
      "loss: 0.002462  [ 9632/24000]\n",
      "loss: 0.028029  [12832/24000]\n",
      "loss: 0.031061  [16032/24000]\n",
      "loss: 0.095675  [19232/24000]\n",
      "loss: 0.023245  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.083212 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.009928  [   32/24000]\n",
      "loss: 0.048649  [ 3232/24000]\n",
      "loss: 0.014639  [ 6432/24000]\n",
      "loss: 0.013227  [ 9632/24000]\n",
      "loss: 0.053762  [12832/24000]\n",
      "loss: 0.037088  [16032/24000]\n",
      "loss: 0.002488  [19232/24000]\n",
      "loss: 0.007456  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.073846 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.021048  [   32/24000]\n",
      "loss: 0.126284  [ 3232/24000]\n",
      "loss: 0.002188  [ 6432/24000]\n",
      "loss: 0.043121  [ 9632/24000]\n",
      "loss: 0.022166  [12832/24000]\n",
      "loss: 0.072801  [16032/24000]\n",
      "loss: 0.016615  [19232/24000]\n",
      "loss: 0.031031  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.086273 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.219449  [   32/24000]\n",
      "loss: 0.003994  [ 3232/24000]\n",
      "loss: 0.027490  [ 6432/24000]\n",
      "loss: 0.007036  [ 9632/24000]\n",
      "loss: 0.010068  [12832/24000]\n",
      "loss: 0.097340  [16032/24000]\n",
      "loss: 0.005762  [19232/24000]\n",
      "loss: 0.016891  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.078274 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.008407  [   32/24000]\n",
      "loss: 0.026269  [ 3232/24000]\n",
      "loss: 0.003809  [ 6432/24000]\n",
      "loss: 0.056811  [ 9632/24000]\n",
      "loss: 0.001674  [12832/24000]\n",
      "loss: 0.002090  [16032/24000]\n",
      "loss: 0.011879  [19232/24000]\n",
      "loss: 0.179083  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.073418 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.011014  [   32/24000]\n",
      "loss: 0.001015  [ 3232/24000]\n",
      "loss: 0.008092  [ 6432/24000]\n",
      "loss: 0.029792  [ 9632/24000]\n",
      "loss: 0.025141  [12832/24000]\n",
      "loss: 0.022534  [16032/24000]\n",
      "loss: 0.006604  [19232/24000]\n",
      "loss: 0.220583  [22432/24000]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.072974 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\") \n",
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    test(test_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        1\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "23995    1\n",
       "23996    1\n",
       "23997    1\n",
       "23998    0\n",
       "23999    1\n",
       "Name: label, Length: 24000, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>title_char_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>text_char_count</th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>text_sentence_count</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>Punctuate</th>\n",
       "      <th>JJ_density</th>\n",
       "      <th>VBG_density</th>\n",
       "      <th>RB_density</th>\n",
       "      <th>JJ_text</th>\n",
       "      <th>VBG_text</th>\n",
       "      <th>RB_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>346</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.9313</td>\n",
       "      <td>0</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.516129</td>\n",
       "      <td>1.612903</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>3518</td>\n",
       "      <td>346</td>\n",
       "      <td>21</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>1</td>\n",
       "      <td>7.692308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.370200</td>\n",
       "      <td>2.304147</td>\n",
       "      <td>1.689708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>142</td>\n",
       "      <td>16</td>\n",
       "      <td>2792</td>\n",
       "      <td>255</td>\n",
       "      <td>20</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.9777</td>\n",
       "      <td>1</td>\n",
       "      <td>13.636364</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>8.928571</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>3.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>58</td>\n",
       "      <td>8</td>\n",
       "      <td>2095</td>\n",
       "      <td>215</td>\n",
       "      <td>9</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.096</td>\n",
       "      <td>-0.6625</td>\n",
       "      <td>1</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.924119</td>\n",
       "      <td>3.523035</td>\n",
       "      <td>2.981030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>121</td>\n",
       "      <td>16</td>\n",
       "      <td>922</td>\n",
       "      <td>92</td>\n",
       "      <td>4</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>1</td>\n",
       "      <td>13.793103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.448276</td>\n",
       "      <td>6.806283</td>\n",
       "      <td>2.094241</td>\n",
       "      <td>4.712042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23995</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "      <td>5705</td>\n",
       "      <td>566</td>\n",
       "      <td>36</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>1</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.414560</td>\n",
       "      <td>3.741153</td>\n",
       "      <td>2.527806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>9</td>\n",
       "      <td>757</td>\n",
       "      <td>76</td>\n",
       "      <td>5</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>1</td>\n",
       "      <td>18.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.904110</td>\n",
       "      <td>2.739726</td>\n",
       "      <td>3.424658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>10</td>\n",
       "      <td>473</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.7311</td>\n",
       "      <td>1</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.862745</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.960784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23998</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>956</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.9538</td>\n",
       "      <td>1</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.714286</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23999</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>8</td>\n",
       "      <td>2533</td>\n",
       "      <td>252</td>\n",
       "      <td>16</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.9901</td>\n",
       "      <td>1</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.172260</td>\n",
       "      <td>2.460850</td>\n",
       "      <td>2.013423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       category_id  title_char_count  title_word_count  text_char_count  \\\n",
       "0                4                51                 8              346   \n",
       "1                1                72                 9             3518   \n",
       "2                3               142                16             2792   \n",
       "3                7                58                 8             2095   \n",
       "4                3               121                16              922   \n",
       "...            ...               ...               ...              ...   \n",
       "23995            1                51                 6             5705   \n",
       "23996            5                66                 9              757   \n",
       "23997            1                78                10              473   \n",
       "23998            3                60                 8              956   \n",
       "23999            1                63                 8             2533   \n",
       "\n",
       "       text_word_count  text_sentence_count    neg    neu    pos  compound  \\\n",
       "0                   34                    2  0.000  0.755  0.245    0.9313   \n",
       "1                  346                   21  0.042  0.869  0.089    0.9682   \n",
       "2                  255                   20  0.082  0.886  0.032   -0.9777   \n",
       "3                  215                    9  0.110  0.793  0.096   -0.6625   \n",
       "4                   92                    4  0.100  0.795  0.105    0.2462   \n",
       "...                ...                  ...    ...    ...    ...       ...   \n",
       "23995              566                   36  0.050  0.819  0.131    0.9981   \n",
       "23996               76                    5  0.014  0.919  0.067    0.8074   \n",
       "23997               51                    4  0.082  0.918  0.000   -0.7311   \n",
       "23998              100                    8  0.160  0.782  0.058   -0.9538   \n",
       "23999              252                   16  0.132  0.824  0.044   -0.9901   \n",
       "\n",
       "       Punctuate  JJ_density  VBG_density  RB_density    JJ_text  VBG_text  \\\n",
       "0              0    8.333333     0.000000    0.000000  14.516129  1.612903   \n",
       "1              1    7.692308     0.000000    0.000000   9.370200  2.304147   \n",
       "2              1   13.636364     4.545455    4.545455   8.928571  1.785714   \n",
       "3              1   20.000000     0.000000    0.000000  11.924119  3.523035   \n",
       "4              1   13.793103     0.000000    3.448276   6.806283  2.094241   \n",
       "...          ...         ...          ...         ...        ...       ...   \n",
       "23995          1   42.857143     0.000000    0.000000  10.414560  3.741153   \n",
       "23996          1   18.181818     0.000000    0.000000   8.904110  2.739726   \n",
       "23997          1    6.666667     0.000000    0.000000   6.862745  0.980392   \n",
       "23998          1   20.000000    10.000000    0.000000  13.714286  1.142857   \n",
       "23999          1    9.090909     0.000000    0.000000   9.172260  2.460850   \n",
       "\n",
       "        RB_text  \n",
       "0      0.000000  \n",
       "1      1.689708  \n",
       "2      3.214286  \n",
       "3      2.981030  \n",
       "4      4.712042  \n",
       "...         ...  \n",
       "23995  2.527806  \n",
       "23996  3.424658  \n",
       "23997  1.960784  \n",
       "23998  0.571429  \n",
       "23999  2.013423  \n",
       "\n",
       "[24000 rows x 17 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalNetwork(\n",
       "  (conv_layer): Sequential(\n",
       "    (0): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): Tanh()\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (4): Tanh()\n",
       "    (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (7): Tanh()\n",
       "    (8): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (10): Tanh()\n",
       "    (11): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (13): Tanh()\n",
       "  )\n",
       "  (fc_layer): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert test data to tensor\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():  # Disable gradient calculation\n",
    "#     outputs = model(X_test_tensor)  # Get logits\n",
    "#     probabilities = torch.sigmoid(outputs)  # Apply sigmoid for probabilities\n",
    "#     predictions = (probabilities > 0.5).float()  # Convert to 0 or 1\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    outputs = model(X_test_tensor)  # Get logits (size: [batch_size, 2])\n",
    "    probabilities = torch.softmax(outputs, dim=1)  # Apply softmax to get class probabilities\n",
    "    predictions = torch.argmax(probabilities, dim=1)  #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 6000\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictions.cpu().numpy()\n",
    "y_true = y_test_tensor.view(-1).cpu().numpy()\n",
    "print(len(y_pred), len(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.60%\n"
     ]
    }
   ],
   "source": [
    "accuracy = (y_pred == y_true).sum() / len(y_true)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8104</td>\n",
       "      <td>Conservatives Will HATE What Donald Trump Just...</td>\n",
       "      <td>Donald Trump isn t exactly a stranger to makin...</td>\n",
       "      <td>News</td>\n",
       "      <td>February 14, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7467</td>\n",
       "      <td>Trump victory may create new tension between U...</td>\n",
       "      <td>Donald Trump’s U.S. election victory may creat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>November 9, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9473</td>\n",
       "      <td>WATCH: Hundreds of ILLEGAL ALIENS Storm Senate...</td>\n",
       "      <td>A couple of quick questions come to mind when ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Nov 9, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276</td>\n",
       "      <td>Democratic Senator Franken to resign: CNN, cit...</td>\n",
       "      <td>U.S. Democratic Senator Al Franken will announ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 7, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19274</td>\n",
       "      <td>GANG OF DOMESTIC TERRORISTS Violently Attack L...</td>\n",
       "      <td>***WARNING*** Violence is graphic***This Trump...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Jan 21, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8104  Conservatives Will HATE What Donald Trump Just...   \n",
       "1        7467  Trump victory may create new tension between U...   \n",
       "2        9473  WATCH: Hundreds of ILLEGAL ALIENS Storm Senate...   \n",
       "3         276  Democratic Senator Franken to resign: CNN, cit...   \n",
       "4       19274  GANG OF DOMESTIC TERRORISTS Violently Attack L...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  Donald Trump isn t exactly a stranger to makin...          News   \n",
       "1  Donald Trump’s U.S. election victory may creat...  politicsNews   \n",
       "2  A couple of quick questions come to mind when ...      politics   \n",
       "3  U.S. Democratic Senator Al Franken will announ...  politicsNews   \n",
       "4  ***WARNING*** Violence is graphic***This Trump...     left-news   \n",
       "\n",
       "                date  label  \n",
       "0  February 14, 2016      0  \n",
       "1  November 9, 2016       1  \n",
       "2        Nov 9, 2017      0  \n",
       "3  December 7, 2017       1  \n",
       "4       Jan 21, 2017      0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(columns = \"Unnamed: 0\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Conservatives Will HATE What Donald Trump Just...</td>\n",
       "      <td>Donald Trump isn t exactly a stranger to makin...</td>\n",
       "      <td>News</td>\n",
       "      <td>February 14, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trump victory may create new tension between U...</td>\n",
       "      <td>Donald Trump’s U.S. election victory may creat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>November 9, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WATCH: Hundreds of ILLEGAL ALIENS Storm Senate...</td>\n",
       "      <td>A couple of quick questions come to mind when ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Nov 9, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Democratic Senator Franken to resign: CNN, cit...</td>\n",
       "      <td>U.S. Democratic Senator Al Franken will announ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 7, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GANG OF DOMESTIC TERRORISTS Violently Attack L...</td>\n",
       "      <td>***WARNING*** Violence is graphic***This Trump...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Jan 21, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Conservatives Will HATE What Donald Trump Just...   \n",
       "1  Trump victory may create new tension between U...   \n",
       "2  WATCH: Hundreds of ILLEGAL ALIENS Storm Senate...   \n",
       "3  Democratic Senator Franken to resign: CNN, cit...   \n",
       "4  GANG OF DOMESTIC TERRORISTS Violently Attack L...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  Donald Trump isn t exactly a stranger to makin...          News   \n",
       "1  Donald Trump’s U.S. election victory may creat...  politicsNews   \n",
       "2  A couple of quick questions come to mind when ...      politics   \n",
       "3  U.S. Democratic Senator Al Franken will announ...  politicsNews   \n",
       "4  ***WARNING*** Violence is graphic***This Trump...     left-news   \n",
       "\n",
       "                date  label  \n",
       "0  February 14, 2016      0  \n",
       "1  November 9, 2016       1  \n",
       "2        Nov 9, 2017      0  \n",
       "3  December 7, 2017       1  \n",
       "4       Jan 21, 2017      0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cat = pd.read_csv(\"test_categories.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tit_len_test = pd.read_csv(\"test_title_length.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_length_test = pd.read_csv(\"test_text_length.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_train_outputs_text_test = pd.read_csv(\"vader_test_outputs_text.csv\")\n",
    "vader_train_outputs_title_test = pd.read_csv(\"vader_test_outputs_title.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: Punctuate, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuated_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>title_char_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>text_char_count</th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>text_sentence_count</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>Punctuate</th>\n",
       "      <th>JJ_density</th>\n",
       "      <th>VBG_density</th>\n",
       "      <th>RB_density</th>\n",
       "      <th>JJ_text</th>\n",
       "      <th>VBG_text</th>\n",
       "      <th>RB_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>84</td>\n",
       "      <td>8</td>\n",
       "      <td>2290</td>\n",
       "      <td>209</td>\n",
       "      <td>15</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.9849</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>6.733167</td>\n",
       "      <td>2.743142</td>\n",
       "      <td>5.486284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>11</td>\n",
       "      <td>658</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>1</td>\n",
       "      <td>21.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.516129</td>\n",
       "      <td>2.419355</td>\n",
       "      <td>2.419355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "      <td>2644</td>\n",
       "      <td>242</td>\n",
       "      <td>17</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.8980</td>\n",
       "      <td>1</td>\n",
       "      <td>11.764706</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>10.267857</td>\n",
       "      <td>2.008929</td>\n",
       "      <td>6.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>279</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>1</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.638298</td>\n",
       "      <td>4.255319</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "      <td>15</td>\n",
       "      <td>344</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-0.9206</td>\n",
       "      <td>1</td>\n",
       "      <td>18.181818</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>9.677419</td>\n",
       "      <td>4.838710</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_id  title_char_count  title_word_count  text_char_count  \\\n",
       "0            6                84                 8             2290   \n",
       "1            1                84                11              658   \n",
       "2            4               103                11             2644   \n",
       "3            1                57                 7              279   \n",
       "4            3               123                15              344   \n",
       "\n",
       "   text_word_count  text_sentence_count    neg    neu    pos  compound  \\\n",
       "0              209                   15  0.109  0.724  0.167    0.9849   \n",
       "1               70                    4  0.102  0.771  0.127    0.4215   \n",
       "2              242                   17  0.082  0.872  0.046   -0.8980   \n",
       "3               27                    1  0.050  0.950  0.000   -0.2960   \n",
       "4               26                    1  0.294  0.612  0.093   -0.9206   \n",
       "\n",
       "   Punctuate  JJ_density  VBG_density  RB_density    JJ_text  VBG_text  \\\n",
       "0          1    0.000000     0.000000    7.142857   6.733167  2.743142   \n",
       "1          1   21.428571     0.000000    0.000000  14.516129  2.419355   \n",
       "2          1   11.764706     5.882353    5.882353  10.267857  2.008929   \n",
       "3          1   10.000000    10.000000    0.000000  10.638298  4.255319   \n",
       "4          1   18.181818     4.545455    4.545455   9.677419  4.838710   \n",
       "\n",
       "    RB_text  \n",
       "0  5.486284  \n",
       "1  2.419355  \n",
       "2  6.250000  \n",
       "3  0.000000  \n",
       "4  0.000000  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_test_df = pd.concat([test_cat, test_tit_len_test, train_text_length_test, \n",
    "                       vader_train_outputs_text_test, vader_train_outputs_title_test, punctuated_test_df, keyword_test_title, keyword_test_text], axis=1)\n",
    "merged_test_df = merged_test_df.loc[:, ~merged_test_df.columns.duplicated()]\n",
    "merged_test_df.drop(columns=[\"id\", \"Unnamed: 0\"],inplace=True)\n",
    "merged_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = merged_test_df.values\n",
    "y_test = test_df['label']\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert test data to tensor\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    outputs = model(X_test_tensor)  # Get logits (size: [batch_size, 2])\n",
    "    probabilities = torch.softmax(outputs, dim=1)  # Apply softmax to get class probabilities\n",
    "    predictions = torch.argmax(probabilities, dim=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8267 8267\n",
      "(8267,)\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictions.cpu().numpy()\n",
    "y_true = y_test_tensor.view(-1).cpu().numpy()\n",
    "y_probs = probabilities.cpu().numpy()\n",
    "\n",
    "print(len(y_pred), len(y_true))\n",
    "\n",
    "\n",
    "print(y_probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.69%\n"
     ]
    }
   ],
   "source": [
    "accuracy = (y_pred == y_true).sum() / len(y_true)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      4284\n",
      "           1       0.98      0.97      0.98      3983\n",
      "\n",
      "    accuracy                           0.98      8267\n",
      "   macro avg       0.98      0.98      0.98      8267\n",
      "weighted avg       0.98      0.98      0.98      8267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC Score: 0.9766228694172455\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example binary classification outputs and ground truth\n",
    "y_true = y_test  # Ground truth labels\n",
    "y_scores = y_pred  # Model's predicted probabilities for the positive class\n",
    "\n",
    "# Compute AUC-ROC score\n",
    "auc = roc_auc_score(y_true, y_scores)\n",
    "print(\"AUC-ROC Score:\", auc)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {auc:.2f}\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: torch.Size([8267, 2])\n",
      "y_test_tensor shape: torch.Size([8267, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions shape:\", predictions.shape)       # Before flattening\n",
    "print(\"y_test_tensor shape:\", y_test_tensor.shape)   # Before flattening\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model's state_dict\n",
    "torch.save(model.state_dict(), 'model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model\n",
    "torch.save(model, 'model_complete.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
